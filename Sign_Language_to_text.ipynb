{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**MINOR PROJECT** </center>\n",
    "## <center> **SIGN LANGUAGE TO TEXT** </center>\n",
    "\n",
    "1.Reedam Ranjan (1805686) <br>\n",
    "2.Nandini Kalita (1805675) <br>\n",
    "3.Sourodeep Dhar (1805711)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 — Preparing the Sign Language Classification Dataset(Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "class SignLanguageMNIST(Dataset):\n",
    "    \"\"\"Sign Language classification dataset.\n",
    "\n",
    "    Utility for loading Sign Language dataset into PyTorch. Dataset posted on\n",
    "    Kaggle in 2017, by an unnamed author with username `tecperson`:\n",
    "    https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "\n",
    "    Each sample is 1 x 1 x 28 x 28, and each label is a scalar.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_mapping():\n",
    "        \"\"\"\n",
    "        We map all labels to [0, 23]. This mapping from dataset labels [0, 23]\n",
    "        to letter indices [0, 25] is returned below.\n",
    "        \"\"\"\n",
    "        mapping = list(range(25))\n",
    "        mapping.pop(9)\n",
    "        return mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def read_label_samples_from_csv(path: str):\n",
    "        \"\"\"\n",
    "        Assumes first column in CSV is the label and subsequent 28^2 values\n",
    "        are image pixel values 0-255.\n",
    "        \"\"\"\n",
    "        mapping = SignLanguageMNIST.get_label_mapping()\n",
    "        labels, samples = [], []\n",
    "        with open(path) as f:\n",
    "            _ = next(f)  # skip header\n",
    "            for line in csv.reader(f):\n",
    "                label = int(line[0])\n",
    "                labels.append(mapping.index(label))\n",
    "                samples.append(list(map(int, line[1:])))\n",
    "        return labels, samples\n",
    "\n",
    "    def __init__(self,\n",
    "            path: str=\"data/sign_mnist_train.csv\",\n",
    "            mean: List[float]=[0.485],\n",
    "            std: List[float]=[0.229]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...\n",
    "        \"\"\"\n",
    "        labels, samples = SignLanguageMNIST.read_label_samples_from_csv(path)\n",
    "        self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 28, 28, 1))\n",
    "        self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))\n",
    "\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(28, scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self._mean, std=self._std)])\n",
    "\n",
    "        return {\n",
    "            'image': transform(self._samples[idx]).float(),\n",
    "            'label': torch.from_numpy(self._labels[idx]).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_loaders(batch_size=32):\n",
    "    trainset = SignLanguageMNIST('data/sign_mnist_train.csv')\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    testset = SignLanguageMNIST('data/sign_mnist_test.csv')\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[ 1.5297,  1.5639,  1.6153,  ...,  1.8893,  1.9064,  1.8893],\n",
      "          [ 1.5810,  1.5982,  1.6495,  ...,  1.9064,  1.9235,  1.9064],\n",
      "          [ 1.5982,  1.6153,  1.6667,  ...,  1.9920,  1.9407,  1.9578],\n",
      "          ...,\n",
      "          [ 2.0092,  2.0263,  2.0948,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.9920,  2.0092,  2.0605,  ...,  2.2489,  2.2489,  2.2489],\n",
      "          [ 1.9920,  2.0092,  2.0092,  ...,  2.2489,  2.2489,  2.2489]]],\n",
      "\n",
      "\n",
      "        [[[-0.6281, -0.5082, -0.4226,  ...,  0.0227,  0.0056, -0.0116],\n",
      "          [-0.5596, -0.4568, -0.3712,  ...,  0.0569,  0.0569,  0.0398],\n",
      "          [-0.5253, -0.4054, -0.3027,  ...,  0.1426,  0.1083,  0.0741],\n",
      "          ...,\n",
      "          [ 0.1939,  0.3481,  0.4679,  ...,  0.9646,  0.9474,  0.9303],\n",
      "          [ 0.2111,  0.3652,  0.4851,  ...,  0.9817,  0.9817,  0.9474],\n",
      "          [ 0.2453,  0.3652,  0.4851,  ...,  1.0159,  0.9817,  0.9817]]]]), 'label': tensor([[11.],\n",
      "        [21.]])}\n"
     ]
    }
   ],
   "source": [
    "loader, _ = get_train_test_loaders(2)\n",
    "print(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 — Building and Training the Sign Language Classifier Using Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 6, 3)\n",
    "        self.conv3 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 48)\n",
    "        self.fc3 = nn.Linear(48, 25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    net = Net().float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    trainloader, _ = get_train_test_loaders()\n",
    "    for epoch in range(12):  # loop over the dataset multiple times\n",
    "        train(net, criterion, optimizer, trainloader, epoch)\n",
    "        scheduler.step()\n",
    "    torch.save(net.state_dict(), \"checkpoint.pth\")\n",
    "    \n",
    "\n",
    "\n",
    "def train(net, criterion, optimizer, trainloader, epoch):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs = Variable(data['image'].float())\n",
    "        labels = Variable(data['label'].long())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels[:, 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch, i, running_loss / (i + 1)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     0] loss: 3.208738\n",
      "[0,   100] loss: 3.200263\n",
      "[0,   200] loss: 3.092180\n",
      "[0,   300] loss: 2.823021\n",
      "[0,   400] loss: 2.544829\n",
      "[0,   500] loss: 2.295798\n",
      "[0,   600] loss: 2.086096\n",
      "[0,   700] loss: 1.901347\n",
      "[0,   800] loss: 1.752182\n",
      "[1,     0] loss: 0.402581\n",
      "[1,   100] loss: 0.587778\n",
      "[1,   200] loss: 0.521935\n",
      "[1,   300] loss: 0.469272\n",
      "[1,   400] loss: 0.443803\n",
      "[1,   500] loss: 0.410900\n",
      "[1,   600] loss: 0.387525\n",
      "[1,   700] loss: 0.367853\n",
      "[1,   800] loss: 0.356401\n",
      "[2,     0] loss: 0.293182\n",
      "[2,   100] loss: 0.226374\n",
      "[2,   200] loss: 0.213741\n",
      "[2,   300] loss: 0.201791\n",
      "[2,   400] loss: 0.195854\n",
      "[2,   500] loss: 0.199431\n",
      "[2,   600] loss: 0.196252\n",
      "[2,   700] loss: 0.192126\n",
      "[2,   800] loss: 0.189057\n",
      "[3,     0] loss: 0.179831\n",
      "[3,   100] loss: 0.135088\n",
      "[3,   200] loss: 0.126435\n",
      "[3,   300] loss: 0.131538\n",
      "[3,   400] loss: 0.131001\n",
      "[3,   500] loss: 0.126668\n",
      "[3,   600] loss: 0.124353\n",
      "[3,   700] loss: 0.125315\n",
      "[3,   800] loss: 0.117626\n",
      "[4,     0] loss: 0.053651\n",
      "[4,   100] loss: 0.078640\n",
      "[4,   200] loss: 0.098296\n",
      "[4,   300] loss: 0.092707\n",
      "[4,   400] loss: 0.095541\n",
      "[4,   500] loss: 0.093223\n",
      "[4,   600] loss: 0.095191\n",
      "[4,   700] loss: 0.093007\n",
      "[4,   800] loss: 0.091415\n",
      "[5,     0] loss: 0.220986\n",
      "[5,   100] loss: 0.072156\n",
      "[5,   200] loss: 0.066175\n",
      "[5,   300] loss: 0.072518\n",
      "[5,   400] loss: 0.069935\n",
      "[5,   500] loss: 0.076354\n",
      "[5,   600] loss: 0.077436\n",
      "[5,   700] loss: 0.078336\n",
      "[5,   800] loss: 0.077679\n",
      "[6,     0] loss: 0.097652\n",
      "[6,   100] loss: 0.092629\n",
      "[6,   200] loss: 0.077814\n",
      "[6,   300] loss: 0.070938\n",
      "[6,   400] loss: 0.069759\n",
      "[6,   500] loss: 0.069550\n",
      "[6,   600] loss: 0.068010\n",
      "[6,   700] loss: 0.068416\n",
      "[6,   800] loss: 0.068792\n",
      "[7,     0] loss: 0.255253\n",
      "[7,   100] loss: 0.064881\n",
      "[7,   200] loss: 0.053345\n",
      "[7,   300] loss: 0.053254\n",
      "[7,   400] loss: 0.054440\n",
      "[7,   500] loss: 0.055907\n",
      "[7,   600] loss: 0.060131\n",
      "[7,   700] loss: 0.055219\n",
      "[7,   800] loss: 0.054243\n",
      "[8,     0] loss: 0.016892\n",
      "[8,   100] loss: 0.068176\n",
      "[8,   200] loss: 0.074856\n",
      "[8,   300] loss: 0.070642\n",
      "[8,   400] loss: 0.071385\n",
      "[8,   500] loss: 0.071930\n",
      "[8,   600] loss: 0.069710\n",
      "[8,   700] loss: 0.065403\n",
      "[8,   800] loss: 0.062106\n",
      "[9,     0] loss: 0.006863\n",
      "[9,   100] loss: 0.046266\n",
      "[9,   200] loss: 0.041684\n",
      "[9,   300] loss: 0.041220\n",
      "[9,   400] loss: 0.042840\n",
      "[9,   500] loss: 0.041203\n",
      "[9,   600] loss: 0.042788\n",
      "[9,   700] loss: 0.041820\n",
      "[9,   800] loss: 0.041708\n",
      "[10,     0] loss: 0.011129\n",
      "[10,   100] loss: 0.016724\n",
      "[10,   200] loss: 0.016143\n",
      "[10,   300] loss: 0.013809\n",
      "[10,   400] loss: 0.012902\n",
      "[10,   500] loss: 0.013861\n",
      "[10,   600] loss: 0.012593\n",
      "[10,   700] loss: 0.013469\n",
      "[10,   800] loss: 0.013295\n",
      "[11,     0] loss: 0.002194\n",
      "[11,   100] loss: 0.008843\n",
      "[11,   200] loss: 0.007956\n",
      "[11,   300] loss: 0.009282\n",
      "[11,   400] loss: 0.009976\n",
      "[11,   500] loss: 0.009226\n",
      "[11,   600] loss: 0.009487\n",
      "[11,   700] loss: 0.009949\n",
      "[11,   800] loss: 0.009356\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3 — Evaluating the Sign Language Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(outputs: Variable, labels: Variable) -> float:\n",
    "    \"\"\"Evaluate neural network outputs against non-one-hotted labels.\"\"\"\n",
    "    Y = labels.numpy()\n",
    "    Yhat = np.argmax(outputs, axis=1)\n",
    "    return float(np.sum(Yhat == Y))\n",
    "\n",
    "\n",
    "def batch_evaluate(\n",
    "        net: Net,\n",
    "        dataloader: torch.utils.data.DataLoader) -> float:\n",
    "    \"\"\"Evaluate neural network in batches, if dataset is too large.\"\"\"\n",
    "    score = n = 0.0\n",
    "    for batch in dataloader:\n",
    "        n += len(batch['image'])\n",
    "        outputs = net(batch['image'])\n",
    "        if isinstance(outputs, torch.Tensor):\n",
    "            outputs = outputs.detach().numpy()\n",
    "        score += evaluate(outputs, batch['label'][:, 0])\n",
    "    return score / n\n",
    "\n",
    "\n",
    "def validate():\n",
    "    trainloader, testloader = get_train_test_loaders()\n",
    "    net = Net().float().eval()\n",
    "\n",
    "    pretrained_model = torch.load(\"checkpoint.pth\")\n",
    "    net.load_state_dict(pretrained_model)\n",
    "\n",
    "    print('=' * 10, 'PyTorch', '=' * 10)\n",
    "    train_acc = batch_evaluate(net, trainloader) * 100.\n",
    "    print('Training accuracy: %.1f' % train_acc)\n",
    "    test_acc = batch_evaluate(net, testloader) * 100.\n",
    "    print('Validation accuracy: %.1f' % test_acc)\n",
    "\n",
    "    trainloader, testloader = get_train_test_loaders(1)\n",
    "\n",
    "    # export to onnx\n",
    "    fname = \"signlanguage.onnx\"\n",
    "    dummy = torch.randn(1, 1, 28, 28)\n",
    "    torch.onnx.export(net, dummy, fname, input_names=['input'])\n",
    "\n",
    "    # check exported model\n",
    "    model = onnx.load(fname)\n",
    "    onnx.checker.check_model(model)  # check model is well-formed\n",
    "\n",
    "    # create runnable session with exported model\n",
    "    ort_session = ort.InferenceSession(fname)\n",
    "    net = lambda inp: ort_session.run(None, {'input': inp.data.numpy()})[0]\n",
    "\n",
    "    print('=' * 10, 'ONNX', '=' * 10)\n",
    "    train_acc = batch_evaluate(net, trainloader) * 100.\n",
    "    print('Training accuracy: %.1f' % train_acc)\n",
    "    test_acc = batch_evaluate(net, testloader) * 100.\n",
    "    print('Validation accuracy: %.1f' % test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== PyTorch ==========\n",
      "Training accuracy: 99.7\n",
      "Validation accuracy: 96.6\n",
      "========== ONNX ==========\n",
      "Training accuracy: 99.7\n",
      "Validation accuracy: 96.8\n"
     ]
    }
   ],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 — Linking the Camera Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "def center_crop(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    start = abs(h - w) // 2\n",
    "    if h > w:\n",
    "        return frame[start: start + w]\n",
    "    return frame[:, start: start + h]\n",
    "\n",
    "\n",
    "def main_ca():\n",
    "    # constants\n",
    "    index_to_letter = list('ABCDEFGHIKLMNOPQRSTUVWXY')\n",
    "    mean = 0.485 * 255.\n",
    "    std = 0.229 * 255.\n",
    "\n",
    "    # create runnable session with exported model\n",
    "    ort_session = ort.InferenceSession(\"signlanguage.onnx\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # preprocess data\n",
    "        frame = center_crop(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        x = cv2.resize(frame, (28, 28))\n",
    "        x = (x - mean) / std\n",
    "\n",
    "        x = x.reshape(1, 1, 28, 28).astype(np.float32)\n",
    "        y = ort_session.run(None, {'input': x})[0]\n",
    "\n",
    "        index = np.argmax(y, axis=1)\n",
    "        letter = index_to_letter[int(index)]\n",
    "\n",
    "        cv2.putText(frame, letter, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), thickness=2)\n",
    "        cv2.imshow(\"Sign Language Translator\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ca()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
